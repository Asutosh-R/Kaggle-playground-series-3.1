{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please upvote my notebook if You like it! :)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:04.245754Z",
     "iopub.status.busy": "2023-01-09T04:22:04.244855Z",
     "iopub.status.idle": "2023-01-09T04:22:05.467727Z",
     "shell.execute_reply": "2023-01-09T04:22:05.465516Z",
     "shell.execute_reply.started": "2023-01-09T04:22:04.245649Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:05.470958Z",
     "iopub.status.busy": "2023-01-09T04:22:05.470263Z",
     "iopub.status.idle": "2023-01-09T04:22:19.483071Z",
     "shell.execute_reply": "2023-01-09T04:22:19.481896Z",
     "shell.execute_reply.started": "2023-01-09T04:22:05.470919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting reverse_geocoder\n",
      "  Downloading reverse_geocoder-1.5.1.tar.gz (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 85.5 kB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.11.0 in c:\\python39\\lib\\site-packages (from reverse_geocoder) (1.22.3)\n",
      "Requirement already satisfied: scipy>=0.17.1 in c:\\python39\\lib\\site-packages (from reverse_geocoder) (1.8.0)\n",
      "Building wheels for collected packages: reverse_geocoder\n",
      "  Building wheel for reverse_geocoder (setup.py): started\n",
      "  Building wheel for reverse_geocoder (setup.py): finished with status 'done'\n",
      "  Created wheel for reverse_geocoder: filename=reverse_geocoder-1.5.1-py3-none-any.whl size=2268088 sha256=fc9418d739509c24516a445a266dc272b675925f79b5681050dfa4f1ab28301e\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\24\\c4\\5e\\81830841082d64f84d0b36f80589d5af69f3adf2ea3df7e4ef\n",
      "Successfully built reverse_geocoder\n",
      "Installing collected packages: reverse_geocoder\n",
      "Successfully installed reverse_geocoder-1.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002AE91CAB460>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed')': /packages/0b/0f/b7d5d4b36553731f11983e19e1813a1059ad0732c5162c01b3220c927d31/reverse_geocoder-1.5.1.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!pip install reverse_geocoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Downloading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:19.485090Z",
     "iopub.status.busy": "2023-01-09T04:22:19.484555Z",
     "iopub.status.idle": "2023-01-09T04:22:19.697971Z",
     "shell.execute_reply": "2023-01-09T04:22:19.695981Z",
     "shell.execute_reply.started": "2023-01-09T04:22:19.485047Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/kaggle/input/playground-series-s3e1/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/playground-series-s3e1/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/playground-series-s3e1/sample_submission.csv')\n",
    "train_df = train_df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:19.700904Z",
     "iopub.status.busy": "2023-01-09T04:22:19.700561Z",
     "iopub.status.idle": "2023-01-09T04:22:21.336250Z",
     "shell.execute_reply": "2023-01-09T04:22:21.334347Z",
     "shell.execute_reply.started": "2023-01-09T04:22:19.700874Z"
    }
   },
   "outputs": [],
   "source": [
    "extra_data = fetch_california_housing()\n",
    "train_data2 = pd.DataFrame(extra_data['data'])\n",
    "train_data2['MedHouseVal'] = extra_data['target']\n",
    "train_data2.columns = train_df.columns\n",
    "train_df['generated'] = 1\n",
    "test_df['generated'] = 1\n",
    "train_data2['generated'] = 0\n",
    "# train_df = pd.concat([train_df, train_data2],axis=0).drop_duplicates()\n",
    "train_df = pd.concat([train_df, train_data2],axis=0, ignore_index=True)\n",
    "\n",
    "train_df.loc[33228,['Latitude','Longitude']] = [32.74, -117]\n",
    "train_df.loc[34363,['Latitude','Longitude']] = [32.71, -117]\n",
    "train_df.loc[20991,['Latitude','Longitude']] = [34.2, -119]\n",
    "\n",
    "print(train_df.shape)\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:21.338673Z",
     "iopub.status.busy": "2023-01-09T04:22:21.338212Z",
     "iopub.status.idle": "2023-01-09T04:22:21.358153Z",
     "shell.execute_reply": "2023-01-09T04:22:21.356503Z",
     "shell.execute_reply.started": "2023-01-09T04:22:21.338620Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['r'] = np.sqrt(train_df['Latitude']**2 + train_df['Longitude']**2)\n",
    "train_df['theta'] = np.arctan2(train_df['Latitude'], train_df['Longitude'])\n",
    "\n",
    "test_df['r'] = np.sqrt(test_df['Latitude']**2 + test_df['Longitude']**2)\n",
    "test_df['theta'] = np.arctan2(test_df['Latitude'], test_df['Longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:21.360496Z",
     "iopub.status.busy": "2023-01-09T04:22:21.359856Z",
     "iopub.status.idle": "2023-01-09T04:22:21.371070Z",
     "shell.execute_reply": "2023-01-09T04:22:21.369929Z",
     "shell.execute_reply.started": "2023-01-09T04:22:21.360456Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_df, test_df], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding trick (see here: https://www.kaggle.com/competitions/playground-series-s3e1/discussion/376210)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:21.374451Z",
     "iopub.status.busy": "2023-01-09T04:22:21.373956Z",
     "iopub.status.idle": "2023-01-09T04:22:21.521925Z",
     "shell.execute_reply": "2023-01-09T04:22:21.520103Z",
     "shell.execute_reply.started": "2023-01-09T04:22:21.374347Z"
    }
   },
   "outputs": [],
   "source": [
    "emb_size = 20\n",
    "precision = 1e6 \n",
    "\n",
    "latlon = np.expand_dims(df[['Latitude', 'Longitude']].values, axis=-1) \n",
    "\n",
    "m = np.exp(np.log(precision) / emb_size) \n",
    "angle_freq = m ** np.arange(emb_size) \n",
    "angle_freq = angle_freq.reshape(1, 1, emb_size) \n",
    "\n",
    "latlon = latlon * angle_freq \n",
    "latlon[..., 0::2] = np.cos(latlon[..., 0::2]) \n",
    "latlon[..., 1::2] = np.sin(latlon[..., 1::2]) \n",
    "latlon = latlon.reshape(-1, 2 * emb_size) \n",
    "\n",
    "df['exp_latlon1'] = [lat[0] for lat in latlon]\n",
    "df['exp_latlon2'] = [lat[1] for lat in latlon]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to @dmitryuarov for feature engineering ideas with coordinates! Please, upvote his notebook: https://www.kaggle.com/code/dmitryuarov/ps-s3e1-coordinates-key-to-victory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:21.524639Z",
     "iopub.status.busy": "2023-01-09T04:22:21.524204Z",
     "iopub.status.idle": "2023-01-09T04:22:21.684112Z",
     "shell.execute_reply": "2023-01-09T04:22:21.683312Z",
     "shell.execute_reply.started": "2023-01-09T04:22:21.524602Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca(data):\n",
    "    '''\n",
    "    input: dataframe containing Latitude(x) and Longitude(y)\n",
    "    '''\n",
    "    coordinates = data[['Latitude','Latitude']].values\n",
    "    pca_obj = PCA().fit(coordinates)\n",
    "    pca_x = pca_obj.transform(data[['Latitude', 'Longitude']].values)[:,0]\n",
    "    pca_y = pca_obj.transform(data[['Latitude', 'Longitude']].values)[:,1]\n",
    "    return pca_x, pca_y\n",
    "\n",
    "# train_df['pca_x'], train_df['pca_y'] = pca(train_df)\n",
    "# test_df['pca_x'], test_df['pca_y'] = pca(test_df)\n",
    "df['pca_x'], df['pca_y'] = pca(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:22:21.686008Z",
     "iopub.status.busy": "2023-01-09T04:22:21.685478Z",
     "iopub.status.idle": "2023-01-09T04:27:17.584818Z",
     "shell.execute_reply": "2023-01-09T04:27:17.583884Z",
     "shell.execute_reply.started": "2023-01-09T04:22:21.685970Z"
    }
   },
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "coordinates = df[['Latitude', 'Longitude']].values\n",
    "umap = UMAP(n_components=2, n_neighbors=50, random_state=228).fit(coordinates)\n",
    "df['umap_lat'] = umap.transform(coordinates)[:,0]\n",
    "df['umap_lon'] = umap.transform(coordinates)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:17.590749Z",
     "iopub.status.busy": "2023-01-09T04:27:17.589284Z",
     "iopub.status.idle": "2023-01-09T04:27:17.608216Z",
     "shell.execute_reply": "2023-01-09T04:27:17.606503Z",
     "shell.execute_reply.started": "2023-01-09T04:27:17.590711Z"
    }
   },
   "outputs": [],
   "source": [
    "def crt_crds(df): \n",
    "    df['rot_15_x'] = (np.cos(np.radians(15)) * df['Longitude']) + \\\n",
    "                      (np.sin(np.radians(15)) * df['Latitude'])\n",
    "    \n",
    "    df['rot_15_y'] = (np.cos(np.radians(15)) * df['Latitude']) + \\\n",
    "                      (np.sin(np.radians(15)) * df['Longitude'])\n",
    "    \n",
    "    df['rot_30_x'] = (np.cos(np.radians(30)) * df['Longitude']) + \\\n",
    "                      (np.sin(np.radians(30)) * df['Latitude'])\n",
    "    \n",
    "    df['rot_30_y'] = (np.cos(np.radians(30)) * df['Latitude']) + \\\n",
    "                      (np.sin(np.radians(30)) * df['Longitude'])\n",
    "    \n",
    "    df['rot_45_x'] = (np.cos(np.radians(45)) * df['Longitude']) + \\\n",
    "                      (np.sin(np.radians(45)) * df['Latitude'])\n",
    "    return df\n",
    "\n",
    "# train_df = crt_crds(train_df)\n",
    "# test_df = crt_crds(test_df)\n",
    "df = crt_crds(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:17.610230Z",
     "iopub.status.busy": "2023-01-09T04:27:17.609662Z",
     "iopub.status.idle": "2023-01-09T04:27:19.381733Z",
     "shell.execute_reply": "2023-01-09T04:27:19.379405Z",
     "shell.execute_reply.started": "2023-01-09T04:27:17.610161Z"
    }
   },
   "outputs": [],
   "source": [
    "import reverse_geocoder as rg\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def geocoder(df):\n",
    "    coordinates = list(zip(df['Latitude'], df['Longitude']))\n",
    "    results = rg.search(coordinates)\n",
    "    return results\n",
    "\n",
    "# results = geocoder(train_df)\n",
    "# train_df['place'] = [x['admin2'] for x in results]\n",
    "# results = geocoder(test_df)\n",
    "# test_df['place'] = [x['admin2'] for x in results]\n",
    "\n",
    "results = geocoder(df)\n",
    "df['place'] = [x['admin2'] for x in results]\n",
    "\n",
    "places = ['Los Angeles County', 'Orange County', 'Kern County',\n",
    "          'Alameda County', 'San Francisco County', 'Ventura County',\n",
    "          'Santa Clara County', 'Fresno County', 'Santa Barbara County',\n",
    "          'Contra Costa County', 'Yolo County', 'Monterey County',\n",
    "          'Riverside County', 'Napa County']\n",
    "\n",
    "def replace(x):\n",
    "    if x in places:\n",
    "        return x\n",
    "    else:\n",
    "        return 'Other'\n",
    "    \n",
    "# train_df['place'] = train_df['place'].apply(lambda x: replace(x))\n",
    "# test_df['place'] = test_df['place'].apply(lambda x: replace(x))\n",
    "\n",
    "df['place'] = df['place'].apply(lambda x: replace(x))\n",
    "\n",
    "# le = LabelEncoder()\n",
    "# train_df['place'] = le.fit_transform(train_df['place'])\n",
    "# test_df['place'] = le.transform(test_df['place'])\n",
    "\n",
    "# test_df = pd.get_dummies(test_df)\n",
    "# train_df = pd.get_dummies(train_df)\n",
    "\n",
    "df = pd.get_dummies(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distances to cities and coast points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:19.384680Z",
     "iopub.status.busy": "2023-01-09T04:27:19.384209Z",
     "iopub.status.idle": "2023-01-09T04:27:26.654320Z",
     "shell.execute_reply": "2023-01-09T04:27:26.652898Z",
     "shell.execute_reply.started": "2023-01-09T04:27:19.384639Z"
    }
   },
   "outputs": [],
   "source": [
    "from haversine import haversine\n",
    "\n",
    "Sac = (38.576931, -121.494949)\n",
    "SF = (37.780080, -122.420160)\n",
    "SJ = (37.334789, -121.888138)\n",
    "LA = (34.052235, -118.243683)\n",
    "SD = (32.715759, -117.163818)\n",
    "\n",
    "df['dist_Sac'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), Sac, unit='ft'), axis=1)\n",
    "df['dist_SF'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), SF, unit='ft'), axis=1)\n",
    "df['dist_SJ'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), SJ, unit='ft'), axis=1)\n",
    "df['dist_LA'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), LA, unit='ft'), axis=1)\n",
    "df['dist_SD'] = df.apply(lambda x: haversine((x['Latitude'], x['Longitude']), SD, unit='ft'), axis=1)\n",
    "df['dist_nearest_city'] = df[['dist_Sac', 'dist_SF', 'dist_SJ', \n",
    "                              'dist_LA', 'dist_SD']].min(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:26.656684Z",
     "iopub.status.busy": "2023-01-09T04:27:26.656294Z",
     "iopub.status.idle": "2023-01-09T04:27:29.355851Z",
     "shell.execute_reply": "2023-01-09T04:27:29.354493Z",
     "shell.execute_reply.started": "2023-01-09T04:27:26.656654Z"
    }
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import LineString, Point\n",
    "\n",
    "coast_points = LineString([(32.6644, -117.1613), (33.2064, -117.3831),\n",
    "                           (33.7772, -118.2024), (34.4634, -120.0144),\n",
    "                           (35.4273, -120.8819), (35.9284, -121.4892),\n",
    "                           (36.9827, -122.0289), (37.6114, -122.4916),\n",
    "                           (38.3556, -123.0603), (39.7926, -123.8217),\n",
    "                           (40.7997, -124.1881), (41.7558, -124.1976)])\n",
    "\n",
    "df['dist_to_coast'] = df.apply(lambda x: Point(x['Latitude'], x['Longitude']).distance(coast_points), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:29.357815Z",
     "iopub.status.busy": "2023-01-09T04:27:29.357461Z",
     "iopub.status.idle": "2023-01-09T04:27:29.675465Z",
     "shell.execute_reply": "2023-01-09T04:27:29.674449Z",
     "shell.execute_reply.started": "2023-01-09T04:27:29.357788Z"
    }
   },
   "outputs": [],
   "source": [
    "# combine latitude and longitude\n",
    "# codes from \n",
    "# https://datascience.stackexchange.com/questions/49553/combining-latitude-longitude-position-into-single-feature\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def single_pt_haversine(lat, lng, degrees=True):\n",
    "    \"\"\"\n",
    "    'Single-point' Haversine: Calculates the great circle distance\n",
    "    between a point on Earth and the (0, 0) lat-long coordinate\n",
    "    \"\"\"\n",
    "    r = 6371 # Earth's radius (km). Have r = 3956 if you want miles\n",
    "\n",
    "    # Convert decimal degrees to radians\n",
    "    if degrees:\n",
    "        lat, lng = map(radians, [lat, lng])\n",
    "\n",
    "    # 'Single-point' Haversine formula\n",
    "    a = sin(lat/2)**2 + cos(lat) * sin(lng/2)**2\n",
    "    d = 2 * r * asin(sqrt(a)) \n",
    "\n",
    "    return d\n",
    "# add more metric \n",
    "# referred to this discussion\n",
    "# https://www.kaggle.com/competitions/playground-series-s3e1/discussion/376210\n",
    "\n",
    "def manhattan(lat,lng):\n",
    "    return np.abs(lat) + np.abs(lng)\n",
    "def euclidean(lat,lng):\n",
    "    return (lat**2 + lng**2) **0.5\n",
    "\n",
    "def add_combine(df):      \n",
    "    df['haversine'] = [single_pt_haversine(x, y) for x, y in zip(df.Latitude, df.Longitude)]\n",
    "    df['manhattan'] = [manhattan(x,y) for x,y in zip(df.Latitude, df.Longitude)]\n",
    "    df['euclidean'] = [euclidean(x,y) for x,y in zip(df.Latitude,df.Longitude)]\n",
    "    return df\n",
    "\n",
    "df = add_combine(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T05:22:41.695979Z",
     "iopub.status.busy": "2023-01-09T05:22:41.695606Z",
     "iopub.status.idle": "2023-01-09T05:22:49.517074Z",
     "shell.execute_reply": "2023-01-09T05:22:49.515604Z",
     "shell.execute_reply.started": "2023-01-09T05:22:41.695951Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# neighbors = 15\n",
    "\n",
    "# knn = KNeighborsRegressor(n_neighbors = neighbors,\n",
    "#                             metric = 'haversine',\n",
    "#                             n_jobs = -1)\n",
    "# knn.fit(df[['Latitude','Longitude']], df.index)\n",
    "# dists, nears = knn.kneighbors(df[['Latitude', 'Longitude']], \n",
    "#                                 return_distance = True)\n",
    "\n",
    "# df[['dist1', 'dist2', 'dist3', 'dist4', 'dist5',\n",
    "#     'dist6', 'dist7', 'dist8', 'dist9', 'dist10',\n",
    "#     'dist11', 'dist12', 'dist13', 'dist14', 'dist15']] = dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['number_houses_per_block'] = df['Population'] / df['AveOccup']\n",
    "# df['total_income_of_block'] = df['MedInc'] * df['Population']\n",
    "# df['occupants_to_bedrooms'] = df['AveOccup'] / df['AveBedrms']\n",
    "# df['total_number_of_rooms'] = df['AveBedrms'] + df['AveRooms']\n",
    "# df['bedrooms_to_rooms'] = df['AveBedrms'] / df['AveRooms']\n",
    "# df['occupants_to_rooms'] = df['AveOccup'] / df['AveRooms']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T07:44:27.466899Z",
     "iopub.status.busy": "2023-01-09T07:44:27.466308Z",
     "iopub.status.idle": "2023-01-09T07:44:27.572853Z",
     "shell.execute_reply": "2023-01-09T07:44:27.570835Z",
     "shell.execute_reply.started": "2023-01-09T07:44:27.466794Z"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:29.724409Z",
     "iopub.status.busy": "2023-01-09T04:27:29.723849Z",
     "iopub.status.idle": "2023-01-09T04:27:29.747813Z",
     "shell.execute_reply": "2023-01-09T04:27:29.746673Z",
     "shell.execute_reply.started": "2023-01-09T04:27:29.724375Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = df.iloc[:-len(test_df),:]\n",
    "test_df = df.iloc[-len(test_df):,:].drop('MedHouseVal', axis=1).reset_index(drop=True)\n",
    "\n",
    "X = train_df.drop(['MedHouseVal', 'id'], axis=1)\n",
    "y = train_df.MedHouseVal\n",
    "X_test = test_df.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Catboost model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-01-09T04:27:29.749837Z",
     "iopub.status.busy": "2023-01-09T04:27:29.749171Z",
     "iopub.status.idle": "2023-01-09T04:27:56.125730Z",
     "shell.execute_reply": "2023-01-09T04:27:56.124022Z",
     "shell.execute_reply.started": "2023-01-09T04:27:29.749801Z"
    }
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "n_folds = 15\n",
    "\n",
    "MAX_ITER = 15000\n",
    "PATIENCE = 1000\n",
    "DISPLAY_FREQ = 100\n",
    "\n",
    "eval_predsCB = []\n",
    "predsCB = []\n",
    "\n",
    "k_fold = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "                'random_seed': 1234,    \n",
    "#                 'learning_rate': 0.1,   # 0.15: 0.5678, 0.12: 0.5685, 0.1: 0.56757, 0.05: 0.57, 0.01, 0.57             \n",
    "                'iterations': MAX_ITER,\n",
    "                'early_stopping_rounds': PATIENCE,\n",
    "#                 'metric_period': DISPLAY_FREQ,\n",
    "                'use_best_model': True,\n",
    "                'eval_metric': 'RMSE',\n",
    "                'verbose': 1000,\n",
    "#                 'task_type': 'GPU'\n",
    "               }\n",
    "\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = catboost.CatBoostRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "          early_stopping_rounds = PATIENCE,\n",
    "#           metric_period = DISPLAY_FREQ\n",
    "         )\n",
    "    predsCB.append(model.predict(X_test))\n",
    "#     eval_predsCB.append(model.predict(X))\n",
    "#     print(\"RMSE valid = {}\".format(mean_squared_error(y_valid, model.predict(X_valid))))\n",
    "#     print(\"RMSE full = {}\".format(mean_squared_error(y, model.predict(X))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.126634Z",
     "iopub.status.idle": "2023-01-09T04:27:56.127019Z",
     "shell.execute_reply": "2023-01-09T04:27:56.126862Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.126845Z"
    }
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# n_folds = 20\n",
    "k_fold = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "\n",
    "eval_predsXB = []\n",
    "predsXB = []\n",
    "\n",
    "PATIENCE = 200\n",
    "\n",
    "MODEL_PARAMS = {       'n_estimators': 1000, #1000, 5000\n",
    "#                        'learning_rate': 0.05,\n",
    "                       'max_depth': 4, # 3\n",
    "                       'colsample_bytree': 0.9, # 0.95\n",
    "                       'subsample': 1,\n",
    "                       'reg_lambda': 20,\n",
    "                       'early_stopping_rounds': PATIENCE,\n",
    "#                        'tree_method': 'gpu_hist',\n",
    "                       'seed': 1\n",
    "}\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = XGBRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "#           early_stopping_rounds = PATIENCE,\n",
    "          verbose = 100\n",
    "         )\n",
    "    predsXB.append(model.predict(X_test))\n",
    "#     eval_predsXB.append(model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LGBM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.128317Z",
     "iopub.status.idle": "2023-01-09T04:27:56.128765Z",
     "shell.execute_reply": "2023-01-09T04:27:56.128573Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.128551Z"
    }
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from lightgbm.sklearn import LGBMRegressor\n",
    "\n",
    "# n_folds = 20\n",
    "k_fold = KFold(n_splits=n_folds, random_state=42, shuffle=True)\n",
    "\n",
    "eval_predsLB = []\n",
    "predsLB = []\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "                       'learning_rate': 0.01,\n",
    "                       'max_depth': 9,\n",
    "                       'num_leaves': 90,\n",
    "                       'colsample_bytree': 0.8,\n",
    "                       'subsample': 0.9,\n",
    "                       'subsample_freq': 5,\n",
    "                       'min_child_samples': 36,\n",
    "                       'reg_lambda': 28,\n",
    "                       'n_estimators': 20000,\n",
    "                       'metric': 'rmse',\n",
    "                       'random_state': 1\n",
    "}\n",
    "\n",
    "callbacks = [lgbm.early_stopping(30, verbose=1), lgbm.log_evaluation(period=0)]\n",
    "\n",
    "for train_index, test_index in k_fold.split(X, y):\n",
    "    X_train, X_valid = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_valid = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = lgbm.LGBMRegressor(**MODEL_PARAMS)\n",
    "    \n",
    "    model.fit(X=X_train, y=y_train,\n",
    "          eval_set=[(X_valid, y_valid)],\n",
    "#           early_stopping_rounds = PATIENCE,\n",
    "          callbacks=callbacks\n",
    "         )\n",
    "    predsLB.append(model.predict(X_test))\n",
    "#     eval_predsLB.append(model.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.129835Z",
     "iopub.status.idle": "2023-01-09T04:27:56.130340Z",
     "shell.execute_reply": "2023-01-09T04:27:56.130071Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.130051Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(y, np.average(np.array(eval_predsCB),axis=0), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.133651Z",
     "iopub.status.idle": "2023-01-09T04:27:56.134155Z",
     "shell.execute_reply": "2023-01-09T04:27:56.133969Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.133946Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(y, np.average(np.array(eval_predsXB),axis=0), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.135883Z",
     "iopub.status.idle": "2023-01-09T04:27:56.136281Z",
     "shell.execute_reply": "2023-01-09T04:27:56.136111Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.136093Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(y, np.average(np.array(eval_predsLB),axis=0), squared=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.137439Z",
     "iopub.status.idle": "2023-01-09T04:27:56.137729Z",
     "shell.execute_reply": "2023-01-09T04:27:56.137605Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.137592Z"
    }
   },
   "outputs": [],
   "source": [
    "a = 0.4\n",
    "b = 0.2\n",
    "c = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.139421Z",
     "iopub.status.idle": "2023-01-09T04:27:56.139896Z",
     "shell.execute_reply": "2023-01-09T04:27:56.139696Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.139672Z"
    }
   },
   "outputs": [],
   "source": [
    "# mean_squared_error(y, a* np.average(np.array(eval_predsCB),axis=0) + b* np.average(np.array(eval_predsXB),axis=0) + c* np.average(np.array(eval_predsLB),axis=0), squared=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.141118Z",
     "iopub.status.idle": "2023-01-09T04:27:56.141471Z",
     "shell.execute_reply": "2023-01-09T04:27:56.141332Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.141317Z"
    }
   },
   "outputs": [],
   "source": [
    "predCB = np.average(np.array(predsCB),axis=0)\n",
    "predXB = np.average(np.array(predsXB),axis=0)\n",
    "predLB = np.average(np.array(predsLB),axis=0)\n",
    "pred = predCB * a + predXB * b + predLB * c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Making submission**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.142587Z",
     "iopub.status.idle": "2023-01-09T04:27:56.142924Z",
     "shell.execute_reply": "2023-01-09T04:27:56.142772Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.142757Z"
    }
   },
   "outputs": [],
   "source": [
    "submission['MedHouseVal'] = pred\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.144569Z",
     "iopub.status.idle": "2023-01-09T04:27:56.144900Z",
     "shell.execute_reply": "2023-01-09T04:27:56.144755Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.144737Z"
    }
   },
   "outputs": [],
   "source": [
    "vals = train_df['MedHouseVal'].unique().tolist()\n",
    "submission['MedHouseVal'] = submission['MedHouseVal'].apply(lambda x: min(vals, key=lambda v: abs(v - x)))\n",
    "submission.MedHouseVal.clip(0, 5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-01-09T04:27:56.145610Z",
     "iopub.status.idle": "2023-01-09T04:27:56.145884Z",
     "shell.execute_reply": "2023-01-09T04:27:56.145759Z",
     "shell.execute_reply.started": "2023-01-09T04:27:56.145746Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
